{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTOA3yGE7hox"
   },
   "source": [
    "# <font color=blue>Assignments for \"Combining DataFrames\"</font>\n",
    "\n",
    "\n",
    "For Pandas assignments, you are going to use [Titanic](https://www.kaggle.com/c/titanic/download/GQf0y8ebHO0C4JXscPPp%2Fversions%2FXkNkvXwqPPVG0Qt3MtQT%2Ffiles%2Ftrain.csv) (train.csv) dataset. Download the dataset and load to a data frame. We also need [test set](https://www.kaggle.com/c/titanic/download/GQf0y8ebHO0C4JXscPPp%2Fversions%2FXkNkvXwqPPVG0Qt3MtQT%2Ffiles%2Ftest.csv) (test.csv) for this assignment.\n",
    "\n",
    "1. Read both datasets and concatenate test set to train set. Print lenght of new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                 0.0       3   \n",
       "2                 1.0       1   \n",
       "3                 1.0       3   \n",
       "4                 1.0       1   \n",
       "5                 0.0       3   \n",
       "...               ...     ...   \n",
       "1305              NaN       3   \n",
       "1306              NaN       1   \n",
       "1307              NaN       3   \n",
       "1308              NaN       3   \n",
       "1309              NaN       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "1305                                        Spector, Mr. Woolf    male   NaN   \n",
       "1306                              Oliva y Ocana, Dona. Fermina  female  39.0   \n",
       "1307                              Saether, Mr. Simon Sivertsen    male  38.5   \n",
       "1308                                       Ware, Mr. Frederick    male   NaN   \n",
       "1309                                  Peter, Master. Michael J    male   NaN   \n",
       "\n",
       "             SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "PassengerId                                                             \n",
       "1                1      0           A/5 21171    7.2500   NaN        S  \n",
       "2                1      0            PC 17599   71.2833   C85        C  \n",
       "3                0      0    STON/O2. 3101282    7.9250   NaN        S  \n",
       "4                1      0              113803   53.1000  C123        S  \n",
       "5                0      0              373450    8.0500   NaN        S  \n",
       "...            ...    ...                 ...       ...   ...      ...  \n",
       "1305             0      0           A.5. 3236    8.0500   NaN        S  \n",
       "1306             0      0            PC 17758  108.9000  C105        C  \n",
       "1307             0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "1308             0      0              359309    8.0500   NaN        S  \n",
       "1309             1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[1309 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght of new dataset: 1309\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data=pd.read_csv(\"train.csv\", index_col=0)\n",
    "test_data=pd.read_csv(\"test.csv\", index_col=0)\n",
    "# display(train_data)\n",
    "# display(test_data)\n",
    "\n",
    "all_data=pd.concat([train_data,test_data])\n",
    "display(all_data)\n",
    "print(\"lenght of new dataset:\",len(all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Below are 2 groups of values for 2 datasets. The first one is for features and the second one is for target. Using these, create 2 data frames with the methods you have learned in the previous lessons. Then, merge them with all 4 methods and display lenghts of them.\n",
    "\n",
    "```  python\n",
    "id,age,sex,beats_per_sec,cholesterol\n",
    "1001,63,Male,145,233\n",
    "1001,37,Male,130,250\n",
    "1002,41,Female,130,204\n",
    "1002,56,Male,120,236\n",
    "1003,57,Female,120,354\n",
    "1004,57,Male,140,192\n",
    "1005,56,Female,140,294\n",
    "1006,44,Male,120,263\n",
    "1007,52,Male,172,199\n",
    "1007,57,Male,150,168\n",
    "1008,54,Male,140,239\n",
    "1008,48,Female,150,264\n",
    "\n",
    "\n",
    "id,target\n",
    "1001,0\n",
    "1002,1\n",
    "1004,0\n",
    "1005,1\n",
    "1007,0\n",
    "1008,1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lenght inner: 10\n",
      "lenght outer: 12\n",
      "lenght left: 12\n",
      "lenght right: 10\n"
     ]
    }
   ],
   "source": [
    "with open(\"features_data.csv\",'w') as f: \n",
    "    f.write(\"\"\"id,age,sex,beats_per_sec,cholesterol\n",
    "1001,63,Male,145,233\n",
    "1001,37,Male,130,250\n",
    "1002,41,Female,130,204\n",
    "1002,56,Male,120,236\n",
    "1003,57,Female,120,354\n",
    "1004,57,Male,140,192\n",
    "1005,56,Female,140,294\n",
    "1006,44,Male,120,263\n",
    "1007,52,Male,172,199\n",
    "1007,57,Male,150,168\n",
    "1008,54,Male,140,239\n",
    "1008,48,Female,150,264\"\"\")\n",
    "    f.close()\n",
    "\n",
    "with open(\"target_data.csv\",'w') as f2: \n",
    "    f2.write(\"\"\"id,target\n",
    "1001,0\n",
    "1002,1\n",
    "1004,0\n",
    "1005,1\n",
    "1007,0\n",
    "1008,1\"\"\")\n",
    "    f2.close()\n",
    "    \n",
    "features_data=pd.read_csv(\"features_data.csv\", index_col=0)\n",
    "target_data=pd.read_csv(\"target_data.csv\",index_col=0)\n",
    "# display(features_data)\n",
    "# display(target_data)\n",
    "\n",
    "# inner\n",
    "merge_data_in=pd.merge(features_data, target_data, left_on=\"id\", right_on=\"id\",  how = \"inner\")\n",
    "print(\"lenght inner:\",len(merge_data_in))\n",
    "# outer\n",
    "merge_data_out=pd.merge(features_data, target_data, left_on=\"id\", right_on=\"id\",  how = \"outer\")\n",
    "print(\"lenght outer:\",len(merge_data_out))\n",
    "\n",
    "# left\n",
    "merge_data_left=pd.merge(features_data, target_data, left_on=\"id\", right_on=\"id\",  how = \"left\")\n",
    "print(\"lenght left:\", len(merge_data_left))\n",
    "\n",
    "# right\n",
    "merge_data_right=pd.merge(features_data, target_data, left_on=\"id\", right_on=\"id\",  how = \"right\")\n",
    "print(\"lenght right:\", len(merge_data_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
